# AnÃ¡lise Data Analyst - geek.bidu.guru

**Data**: 2025-12-10
**VersÃ£o PRD**: 1.3
**Analista**: Data Analyst
**Documentos**: PRD.md, PRD-affiliate-strategy.md, PRD-internationalization.md, PRD-design-system.md

---

## 1. Resumo Executivo

O projeto possui **KPIs bem definidos** nas seÃ§Ãµes 3 do PRD, mas apresenta **lacunas crÃ­ticas** em especificaÃ§Ã£o tÃ©cnica de tracking, modelagem de dados para analytics, dashboards operacionais e automaÃ§Ãµes de insights.

**Score de Maturidade Analytics: 6.5/10** - KPIs definidos, mas falta implementaÃ§Ã£o tÃ©cnica detalhada.

**Oportunidades principais**: Data warehouse (BigQuery), cohort analysis, predictive analytics, real-time dashboards, attribution modeling e automaÃ§Ã£o de alertas podem **3-5x a eficiÃªncia** na tomada de decisÃ£o.

---

## 2. TOP 5 GAPS CRÃTICOS

### 2.1. Tracking Plan (GA4) NÃ£o Documentado
**Severidade**: Alta
**Impacto**: Dados inconsistentes, impossibilidade de medir KPIs definidos

**O que falta**: EspecificaÃ§Ã£o completa de eventos GA4, parÃ¢metros, triggers, data layer.

### 2.2. Modelagem de Dados para Analytics Incompleta
**Severidade**: Alta
**Impacto**: Queries lentas, impossibilidade de anÃ¡lises complexas

**O que falta**: Tabelas de fatos/dimensÃµes, Ã­ndices, views materializadas, procedures.

### 2.3. Dashboards Operacionais NÃ£o Especificados
**Severidade**: MÃ©dia-Alta
**Impacto**: DecisÃµes baseadas em intuiÃ§Ã£o ao invÃ©s de dados

**O que falta**: Mockups, queries SQL, mÃ©tricas por dashboard, refresh rate.

### 2.4. Sistema de Alertas AutomÃ¡ticos NÃ£o Implementado
**Severidade**: MÃ©dia
**Impacto**: Problemas descobertos tarde demais

**O que falta**: Thresholds, canais de notificaÃ§Ã£o (Telegram/Slack), automaÃ§Ãµes n8n.

### 2.5. Attribution Modeling NÃ£o Definido
**Severidade**: MÃ©dia
**Impacto**: Impossibilidade de otimizar mix de canais

**O que falta**: Modelo de atribuiÃ§Ã£o (first-click, last-click, linear, data-driven).

---

## 3. TOP 5 OPORTUNIDADES

### 3.1. Data Warehouse (BigQuery) + Looker Studio
**Potencial**: AltÃ­ssimo
**EsforÃ§o**: Alto

Export GA4 â†’ BigQuery permite anÃ¡lises SQL avanÃ§adas, cohorts, LTV, custom funnels.

**BenefÃ­cio**: 10x mais poder analÃ­tico, queries complexas em segundos.

### 3.2. Real-Time Dashboard (WebSockets)
**Potencial**: Alto
**EsforÃ§o**: MÃ©dio

Dashboard ao vivo com mÃ©tricas em tempo real (visitantes online, cliques afiliados Ãºltimas 24h).

**BenefÃ­cio**: DecisÃµes rÃ¡pidas, detecÃ§Ã£o imediata de anomalias.

### 3.3. Cohort Analysis & LTV
**Potencial**: Alto
**EsforÃ§o**: MÃ©dio

Agrupar usuÃ¡rios por mÃªs de aquisiÃ§Ã£o, analisar retenÃ§Ã£o e valor no tempo.

**BenefÃ­cio**: Otimizar CAC vs LTV, identificar perÃ­odos mais lucrativos.

### 3.4. Predictive Analytics (Churn, ConversÃ£o)
**Potencial**: MÃ©dio-Alto
**EsforÃ§o**: Alto

ML para prever probabilidade de conversÃ£o, churn de usuÃ¡rios, produtos que vÃ£o trend.

**BenefÃ­cio**: AÃ§Ãµes proativas, personalizaÃ§Ã£o avanÃ§ada.

### 3.5. Automated Insights (Anomaly Detection)
**Potencial**: Alto
**EsforÃ§o**: MÃ©dio

Sistema que detecta automaticamente quedas/picos e gera insights.

**BenefÃ­cio**: Economia de tempo, insights que passariam despercebidos.

---

## 4. GAPS DETALHADOS (12 identificados)

### 2.1. Tracking Plan GA4 NÃ£o Documentado

**Eventos crÃ­ticos faltando especificaÃ§Ã£o**:

```javascript
// EVENTOS DE AFILIADOS
gtag('event', 'affiliate_click', {
  product_id: 'prod-123',
  product_name: 'Caneca Baby Yoda',
  platform: 'amazon',  // ou 'mercadolivre', 'shopee'
  price: 89.90,
  post_slug: 'caneca-baby-yoda',
  link_position: 'top',  // 'middle', 'bottom'
  device: 'mobile',  // 'desktop', 'tablet'
  affiliate_score: 85  // scorecard do produto
});

// SCROLL DEPTH
gtag('event', 'scroll', {
  percent_scrolled: 25,  // 25%, 50%, 75%, 100%
  page_path: window.location.pathname
});

// NEWSLETTER SIGNUP
gtag('event', 'sign_up', {
  method: 'newsletter',
  source: 'sidebar',  // 'popup', 'inline', 'footer'
  persona_inferred: 'ana'  // baseado em comportamento
});

// COMPARTILHAMENTO
gtag('event', 'share', {
  method: 'whatsapp',  // 'telegram', 'twitter', 'facebook', 'copy_link'
  content_type: 'post',
  item_id: 'post-slug'
});

// SEARCH INTERNO
gtag('event', 'search', {
  search_term: 'presentes atÃ© 100 reais',
  search_results: 15
});

// QUIZ COMPLETION
gtag('event', 'quiz_complete', {
  quiz_name: 'Que Tipo de Geek Ã‰ VocÃª?',
  quiz_result: 'gamer',
  products_recommended: 5
});
```

**ParÃ¢metros personalizados GA4**:
```javascript
// ConfiguraÃ§Ã£o global
gtag('config', 'G-XXXXXXXXXX', {
  custom_map: {
    'dimension1': 'persona_inferred',
    'dimension2': 'affiliate_platform',
    'dimension3': 'price_range',
    'dimension4': 'product_category',
    'metric1': 'affiliate_score'
  }
});
```

### 2.2. Modelagem de Dados para Analytics Incompleta

**Tabelas faltantes**:

```sql
-- Tabela de fatos: sessÃµes agregadas (performance)
CREATE TABLE fact_sessions (
    date DATE NOT NULL,
    hour SMALLINT NOT NULL,
    post_id UUID REFERENCES posts(id),
    device VARCHAR(20),
    source VARCHAR(50),
    persona_inferred VARCHAR(20),
    sessions INT DEFAULT 0,
    pageviews INT DEFAULT 0,
    total_time_seconds INT DEFAULT 0,
    affiliate_clicks INT DEFAULT 0,
    newsletter_signups INT DEFAULT 0,
    PRIMARY KEY (date, hour, post_id, device, source)
);

CREATE INDEX idx_fact_sessions_date ON fact_sessions(date DESC);
CREATE INDEX idx_fact_sessions_post ON fact_sessions(post_id, date DESC);

-- Tabela de fatos: cliques de afiliados (detalhado)
CREATE TABLE fact_affiliate_clicks (
    id UUID PRIMARY KEY DEFAULT gen_random_uuid(),
    clicked_at TIMESTAMP NOT NULL DEFAULT NOW(),
    product_id UUID NOT NULL REFERENCES products(id),
    post_id UUID REFERENCES posts(id),
    session_id VARCHAR(100),
    user_id UUID,
    platform VARCHAR(20) NOT NULL,
    link_position VARCHAR(20),
    device VARCHAR(20),
    country VARCHAR(2),
    region VARCHAR(50),
    city VARCHAR(100),
    scroll_depth_pct SMALLINT,
    time_on_page_seconds INT,
    is_bot BOOLEAN DEFAULT FALSE,
    is_suspicious BOOLEAN DEFAULT FALSE,
    estimated_commission_brl DECIMAL(10,2)
);

CREATE INDEX idx_affiliate_clicks_time ON fact_affiliate_clicks(clicked_at DESC);
CREATE INDEX idx_affiliate_clicks_product ON fact_affiliate_clicks(product_id, clicked_at DESC);
CREATE INDEX idx_affiliate_clicks_post ON fact_affiliate_clicks(post_id, clicked_at DESC);
CREATE INDEX idx_affiliate_clicks_platform ON fact_affiliate_clicks(platform, clicked_at DESC);

-- View materializada: performance diÃ¡ria por post
CREATE MATERIALIZED VIEW mv_daily_post_performance AS
SELECT
    date,
    post_id,
    p.title,
    p.type,
    p.category_id,
    SUM(sessions) as total_sessions,
    SUM(pageviews) as total_pageviews,
    SUM(total_time_seconds) / NULLIF(SUM(sessions), 0) as avg_time_seconds,
    SUM(affiliate_clicks) as total_affiliate_clicks,
    ROUND(SUM(affiliate_clicks)::numeric / NULLIF(SUM(sessions), 0) * 100, 2) as ctr_pct,
    SUM(newsletter_signups) as newsletter_signups
FROM fact_sessions fs
JOIN posts p ON p.id = fs.post_id
GROUP BY date, post_id, p.title, p.type, p.category_id;

CREATE UNIQUE INDEX ON mv_daily_post_performance(date, post_id);

-- Refresh diÃ¡rio via cron
-- REFRESH MATERIALIZED VIEW CONCURRENTLY mv_daily_post_performance;
```

**Procedures para relatÃ³rios**:

```sql
-- Top produtos por receita estimada (Ãºltimo mÃªs)
CREATE OR REPLACE FUNCTION get_top_products_by_revenue(
    days_back INT DEFAULT 30,
    limit_rows INT DEFAULT 10
)
RETURNS TABLE (
    product_id UUID,
    product_name VARCHAR,
    platform VARCHAR,
    total_clicks BIGINT,
    estimated_revenue_brl DECIMAL,
    avg_commission_per_click DECIMAL,
    ctr_vs_views DECIMAL
) AS $$
BEGIN
    RETURN QUERY
    SELECT
        p.id,
        p.name,
        p.platform,
        COUNT(ac.id) as total_clicks,
        SUM(ac.estimated_commission_brl) as estimated_revenue,
        AVG(ac.estimated_commission_brl) as avg_commission,
        ROUND(
            COUNT(ac.id)::numeric /
            NULLIF((SELECT SUM(pageviews) FROM fact_sessions fs
                    JOIN post_products pp ON pp.post_id = fs.post_id
                    WHERE pp.product_id = p.id
                    AND fs.date >= CURRENT_DATE - days_back), 0) * 100,
            2
        ) as ctr
    FROM products p
    LEFT JOIN fact_affiliate_clicks ac ON ac.product_id = p.id
    WHERE ac.clicked_at >= NOW() - (days_back || ' days')::INTERVAL
    GROUP BY p.id, p.name, p.platform
    ORDER BY estimated_revenue DESC
    LIMIT limit_rows;
END;
$$ LANGUAGE plpgsql;
```

### 2.3. Dashboards Operacionais NÃ£o Especificados

**Dashboard 1: Executivo (VisÃ£o Geral DiÃ¡ria)**

```sql
-- Query principal
WITH today_metrics AS (
    SELECT
        SUM(sessions) as sessions_today,
        SUM(pageviews) as pageviews_today,
        SUM(affiliate_clicks) as clicks_today,
        ROUND(SUM(affiliate_clicks)::numeric / NULLIF(SUM(sessions), 0) * 100, 2) as ctr_today
    FROM fact_sessions
    WHERE date = CURRENT_DATE
),
yesterday_metrics AS (
    SELECT
        SUM(sessions) as sessions_yesterday,
        SUM(pageviews) as pageviews_yesterday,
        SUM(affiliate_clicks) as clicks_yesterday
    FROM fact_sessions
    WHERE date = CURRENT_DATE - 1
),
revenue_today AS (
    SELECT
        COUNT(*) as total_clicks,
        SUM(estimated_commission_brl) as revenue_estimate,
        AVG(estimated_commission_brl) as epc
    FROM fact_affiliate_clicks
    WHERE clicked_at >= CURRENT_DATE
)
SELECT
    t.sessions_today,
    ROUND((t.sessions_today - y.sessions_yesterday)::numeric / NULLIF(y.sessions_yesterday, 0) * 100, 1) as sessions_change_pct,
    t.pageviews_today,
    t.clicks_today,
    t.ctr_today,
    r.revenue_estimate,
    r.epc
FROM today_metrics t, yesterday_metrics y, revenue_today r;
```

**Mockup Dashboard Executivo**:
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ GEEK.BIDU.GURU - Dashboard Executivo              â”‚
â”‚ Atualizado: 10/12/2025 15:42 ğŸ”„                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                     â”‚
â”‚ ğŸ“Š HOJE (10/Dez)                                   â”‚
â”‚   â”œâ”€ SessÃµes: 847 (+12% vs ontem) â†—              â”‚
â”‚   â”œâ”€ Pageviews: 2.103 (+15%)                      â”‚
â”‚   â”œâ”€ Cliques Afiliados: 42 (CTR: 5.0%)           â”‚
â”‚   â””â”€ Receita Estimada: R$ 76,80                  â”‚
â”‚                                                     â”‚
â”‚ ğŸ’° ÃšLTIMOS 30 DIAS                                 â”‚
â”‚   â”œâ”€ Receita Total: R$ 1.847,00                   â”‚
â”‚   â”œâ”€ Amazon: R$ 980,00 (53%) ğŸŸ¢                  â”‚
â”‚   â”œâ”€ Mercado Livre: R$ 720,00 (39%) ğŸ”µ          â”‚
â”‚   â””â”€ Shopee: R$ 147,00 (8%) ğŸŸ¡                   â”‚
â”‚                                                     â”‚
â”‚ ğŸ“ˆ TOP 5 POSTS (Ãšltimos 7 dias)                   â”‚
â”‚   1. "10 Presentes Geek de Natal" - R$ 320 | 89â†—â”‚
â”‚   2. "Caneca Baby Yoda Review" - R$ 180 | 67â†—   â”‚
â”‚   3. "Setup Gamer Completo" - R$ 156 | 54â†—      â”‚
â”‚   4. "Presentes atÃ© R$100" - R$ 132 | 48â†—       â”‚
â”‚   5. "Funko Pop: Guia" - R$ 98 | 41â†—            â”‚
â”‚                                                     â”‚
â”‚ âš ï¸ ALERTAS                                         â”‚
â”‚   - Post "Teclado MecÃ¢nico" com CTR abaixo 2%    â”‚
â”‚   - Produto "Mouse Gamer X" indisponÃ­vel          â”‚
â”‚                                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Dashboard 2: Afiliados (Detalhado)**

Queries e mÃ©tricas:
- Performance por plataforma (Amazon vs ML vs Shopee)
- EPC por dispositivo (mobile vs desktop)
- CTR por posiÃ§Ã£o de link (top vs middle vs bottom)
- Heatmap de cliques por hora do dia
- Funil: Pageview â†’ Scroll 50% â†’ Scroll 100% â†’ Click
- Produtos com alto trÃ¡fego mas baixo CTR (oportunidades)

**Dashboard 3: ConteÃºdo**

- Posts publicados vs planejados (calendÃ¡rio editorial)
- DistribuiÃ§Ã£o por tipo (produto Ãºnico 60%, listicle 25%, guia 15%)
- Tempo mÃ©dio na pÃ¡gina por categoria
- Taxa de rejeiÃ§Ã£o por persona inferida
- Content gaps (keywords com impressÃµes mas sem posts)

### 2.4. Sistema de Alertas NÃ£o Implementado

**Alertas prioritÃ¡rios**:

```python
# alerts.py - Executar via cron a cada hora

import psycopg2
import requests
from datetime import datetime, timedelta

def send_telegram(message, level='info'):
    emoji = {'critical': 'ğŸš¨', 'warning': 'âš ï¸', 'info': 'â„¹ï¸', 'success': 'âœ…'}
    bot_token = os.getenv('TELEGRAM_BOT_TOKEN')
    chat_id = os.getenv('TELEGRAM_CHAT_ID')

    formatted = f"{emoji[level]} **geek.bidu.guru**\n{message}"

    requests.post(
        f"https://api.telegram.org/bot{bot_token}/sendMessage",
        json={'chat_id': chat_id, 'text': formatted, 'parse_mode': 'Markdown'}
    )

# ALERTA 1: Queda de trÃ¡fego
def check_traffic_drop(conn):
    query = """
    WITH today AS (
        SELECT SUM(sessions) as sessions_today
        FROM fact_sessions
        WHERE date = CURRENT_DATE AND hour <= EXTRACT(hour FROM NOW())
    ),
    last_week AS (
        SELECT SUM(sessions) as sessions_last_week
        FROM fact_sessions
        WHERE date = CURRENT_DATE - 7 AND hour <= EXTRACT(hour FROM NOW())
    )
    SELECT
        t.sessions_today,
        l.sessions_last_week,
        ROUND((t.sessions_today - l.sessions_last_week)::numeric /
              NULLIF(l.sessions_last_week, 0) * 100, 1) as change_pct
    FROM today t, last_week l;
    """
    cur = conn.cursor()
    cur.execute(query)
    row = cur.fetchone()

    if row and row[2] < -30:  # Queda > 30%
        send_telegram(
            f"âš ï¸ **Queda de TrÃ¡fego**\n"
            f"Hoje: {row[0]} sessÃµes\n"
            f"Semana passada (mesmo horÃ¡rio): {row[1]}\n"
            f"VariaÃ§Ã£o: {row[2]}%",
            level='warning'
        )

# ALERTA 2: CTR de afiliados baixo
def check_low_ctr(conn):
    query = """
    SELECT
        ROUND(COUNT(ac.id)::numeric / NULLIF(SUM(fs.sessions), 0) * 100, 2) as ctr
    FROM fact_sessions fs
    LEFT JOIN fact_affiliate_clicks ac ON ac.clicked_at >= CURRENT_DATE
    WHERE fs.date >= CURRENT_DATE - 7;
    """
    cur = conn.cursor()
    cur.execute(query)
    ctr = cur.fetchone()[0]

    if ctr and ctr < 2.0:  # CTR < 2%
        send_telegram(
            f"âš ï¸ **CTR Afiliados Baixo**\n"
            f"CTR Ãºltimos 7 dias: {ctr}%\n"
            f"Meta: >= 3%\n"
            f"AÃ§Ã£o: Revisar CTAs e posicionamento",
            level='warning'
        )

# ALERTA 3: Produto indisponÃ­vel em post popular
def check_unavailable_products(conn):
    query = """
    SELECT p.name, pr.title, pr.slug
    FROM products p
    JOIN post_products pp ON pp.product_id = p.id
    JOIN posts pr ON pr.id = pp.post_id
    JOIN mv_daily_post_performance dp ON dp.post_id = pr.id
    WHERE p.availability = 'unavailable'
    AND dp.date >= CURRENT_DATE - 7
    AND dp.total_sessions > 100
    LIMIT 5;
    """
    cur = conn.cursor()
    cur.execute(query)
    rows = cur.fetchall()

    if rows:
        msg = "âš ï¸ **Produtos IndisponÃ­veis em Posts Populares**\n\n"
        for row in rows:
            msg += f"- {row[0]} em '{row[1]}' ({row[2]})\n"
        send_telegram(msg, level='warning')

# ALERTA 4: Novo post no Top 10 (sucesso!)
def check_new_top_performer(conn):
    query = """
    SELECT p.title, p.slug, dp.total_sessions, dp.ctr_pct
    FROM mv_daily_post_performance dp
    JOIN posts p ON p.id = dp.post_id
    WHERE dp.date = CURRENT_DATE - 1
    AND p.publish_at >= CURRENT_DATE - 30
    ORDER BY dp.total_sessions DESC
    LIMIT 10;
    """
    cur = conn.cursor()
    cur.execute(query)
    rows = cur.fetchall()

    if rows:
        top = rows[0]
        send_telegram(
            f"âœ… **Novo Post de Sucesso!**\n"
            f"'{top[0]}' teve {top[2]} sessÃµes ontem\n"
            f"CTR: {top[3]}%\n"
            f"Link: geek.bidu.guru/{top[1]}",
            level='success'
        )

# Executar todos os checks
if __name__ == '__main__':
    conn = psycopg2.connect(os.getenv('DATABASE_URL'))
    check_traffic_drop(conn)
    check_low_ctr(conn)
    check_unavailable_products(conn)
    check_new_top_performer(conn)
    conn.close()
```

### 2.5. Attribution Modeling NÃ£o Definido

**Problema**: PRD nÃ£o especifica como atribuir conversÃµes quando usuÃ¡rio visita mÃºltiplas vezes por diferentes canais.

**Modelos sugeridos**:

```
CENÃRIO: UsuÃ¡rio visita 3x antes de clicar em afiliado
â”œâ”€ Visita 1: Google OrgÃ¢nico â†’ Post "10 Presentes Geek"
â”œâ”€ Visita 2: Direto â†’ Homepage
â””â”€ Visita 3: Newsletter â†’ Post "Caneca Baby Yoda" â†’ CLICK

MODELOS DE ATRIBUIÃ‡ÃƒO:
â”œâ”€ First-Click: 100% crÃ©dito para Google OrgÃ¢nico
â”œâ”€ Last-Click: 100% crÃ©dito para Newsletter
â”œâ”€ Linear: 33% Google, 33% Direto, 33% Newsletter
â”œâ”€ Time-Decay: 20% Google, 30% Direto, 50% Newsletter
â””â”€ Data-Driven (ML): Baseado em padrÃµes histÃ³ricos
```

**ImplementaÃ§Ã£o recomendada**: Last-Click (simples) na Fase 1, Linear na Fase 2, Data-Driven na Fase 3.

**Tabela necessÃ¡ria**:
```sql
CREATE TABLE user_touchpoints (
    id UUID PRIMARY KEY,
    session_id VARCHAR(100),
    user_id UUID,
    touchpoint_at TIMESTAMP NOT NULL,
    source VARCHAR(50),
    medium VARCHAR(50),
    campaign VARCHAR(100),
    content VARCHAR(200),
    post_id UUID,
    is_conversion BOOLEAN DEFAULT FALSE
);
```

### 2.6. Cohort Analysis NÃ£o Implementado

**O que falta**: Queries e dashboards para anÃ¡lise de cohorts (usuÃ¡rios agrupados por mÃªs de aquisiÃ§Ã£o).

**Query sugerida**:
```sql
-- RetenÃ§Ã£o por cohort (mÃªs de primeira visita)
WITH cohorts AS (
    SELECT
        user_id,
        DATE_TRUNC('month', MIN(session_start)) as cohort_month
    FROM user_sessions
    GROUP BY user_id
),
cohort_activity AS (
    SELECT
        c.cohort_month,
        DATE_TRUNC('month', us.session_start) as activity_month,
        COUNT(DISTINCT us.user_id) as active_users
    FROM cohorts c
    JOIN user_sessions us ON us.user_id = c.user_id
    GROUP BY c.cohort_month, DATE_TRUNC('month', us.session_start)
),
cohort_size AS (
    SELECT cohort_month, COUNT(*) as cohort_size
    FROM cohorts
    GROUP BY cohort_month
)
SELECT
    ca.cohort_month,
    cs.cohort_size,
    ca.activity_month,
    EXTRACT(month FROM AGE(ca.activity_month, ca.cohort_month)) as months_since_acquisition,
    ca.active_users,
    ROUND(ca.active_users::numeric / cs.cohort_size * 100, 1) as retention_pct
FROM cohort_activity ca
JOIN cohort_size cs ON cs.cohort_month = ca.cohort_month
ORDER BY ca.cohort_month, months_since_acquisition;
```

**VisualizaÃ§Ã£o sugerida**: Heatmap com cohort_month no eixo Y e months_since_acquisition no eixo X.

### 2.7. Funis de ConversÃ£o NÃ£o Instrumentados

**Funil 1: TrÃ¡fego OrgÃ¢nico â†’ ConversÃ£o Afiliados**
```
Google Search â†’ Landing Page â†’ Scroll 50% â†’ Scroll 100% â†’ Click Afiliado
       â†“            â†“              â†“              â†“               â†“
    10.000       7.500 (75%)    5.250 (70%)    3.675 (70%)     294 (8%)
```

**Funil 2: Newsletter â†’ ConversÃ£o**
```
Newsletter Sent â†’ Open â†’ Click Post â†’ Click Afiliado
       â†“            â†“         â†“             â†“
     5.000      2.000 (40%)  800 (40%)    64 (8%)
```

**ImplementaÃ§Ã£o**: Eventos GA4 + tabela `funnel_events` no PostgreSQL para anÃ¡lise SQL.

### 2.8. Testes A/B NÃ£o Estruturados

**PRD menciona framework A/B** (seÃ§Ã£o 9.5) mas falta:
- Calculadora de tamanho de amostra
- SignificÃ¢ncia estatÃ­stica (chi-square test)
- Duration mÃ­nima (1-2 semanas)
- DocumentaÃ§Ã£o de hipÃ³teses

**FunÃ§Ã£o SQL sugerida**:
```sql
CREATE OR REPLACE FUNCTION analyze_ab_test(test_id_param UUID)
RETURNS TABLE (
    variant CHAR(1),
    exposures BIGINT,
    conversions BIGINT,
    conversion_rate DECIMAL,
    confidence_95_lower DECIMAL,
    confidence_95_upper DECIMAL,
    p_value DECIMAL,
    is_significant BOOLEAN
) AS $$
-- Implementar chi-square test e confidence intervals
-- ...
$$ LANGUAGE plpgsql;
```

### 2.9. LTV (Lifetime Value) NÃ£o Calculado

**O que falta**: MÃ©trica de valor no tempo de cada usuÃ¡rio.

**CÃ¡lculo simples**:
```sql
SELECT
    user_id,
    COUNT(DISTINCT session_id) as total_sessions,
    SUM(estimated_commission_brl) as total_revenue,
    ROUND(SUM(estimated_commission_brl) / NULLIF(COUNT(DISTINCT session_id), 0), 2) as revenue_per_session,
    DATE_TRUNC('month', MIN(first_session)) as cohort_month,
    EXTRACT(days FROM NOW() - MIN(first_session)) as days_since_acquisition
FROM user_activity_aggregated
GROUP BY user_id;
```

**LTV mÃ©dio por cohort**: Essencial para otimizar CAC (Customer Acquisition Cost) se houver paid ads no futuro.

### 2.10. CAC (Customer Acquisition Cost) NÃ£o Rastreado

**Se implementar paid ads** (Google Ads, Meta Ads), Ã© crÃ­tico rastrear:
```
CAC = Total Spend / New Users Acquired
ROI = (Revenue - Spend) / Spend * 100
```

**Tabela necessÃ¡ria**:
```sql
CREATE TABLE marketing_spend (
    date DATE PRIMARY KEY,
    platform VARCHAR(50),
    campaign VARCHAR(100),
    spend_brl DECIMAL(10,2),
    impressions INT,
    clicks INT,
    new_users INT
);
```

### 2.11. Data Quality Monitoring NÃ£o Implementado

**O que falta**: Sistema que valida dados continuamente.

**Checks prioritÃ¡rios**:
- Eventos GA4 chegando corretamente (volume diÃ¡rio esperado)
- Tabelas fact_* sendo populadas
- PreÃ§os de produtos atualizados (last_price_update < 48h)
- Posts sem produtos associados
- Links de afiliados quebrados

**ImplementaÃ§Ã£o**: Job daily n8n que roda queries de validaÃ§Ã£o e alerta se algo estÃ¡ errado.

### 2.12. Export para BigQuery NÃ£o Configurado

**PRD menciona BigQuery** (seÃ§Ã£o 7) como "opcional" mas Ã© **altamente recomendado**.

**BenefÃ­cios**:
- Queries SQL avanÃ§adas em datasets gigantes
- IntegraÃ§Ã£o nativa com Looker Studio (dashboards)
- Machine Learning integrado (BigQuery ML)
- RetenÃ§Ã£o ilimitada de dados

**Setup**:
1. Habilitar export GA4 â†’ BigQuery (gratuito atÃ© 1M events/dia)
2. Criar scheduled queries para popular tabelas agregadas
3. Conectar Looker Studio para visualizaÃ§Ãµes

---

## 5. OPORTUNIDADES DETALHADAS (10 identificadas)

### 3.1. Data Warehouse (BigQuery) + Looker Studio
**BenefÃ­cio**: AnÃ¡lises SQL avanÃ§adas, dashboards bonitos, compartilhamento fÃ¡cil.
**Custo**: ~$50-200/mÃªs dependendo do volume.

### 3.2. Real-Time Dashboard (WebSockets + Redis)
**BenefÃ­cio**: DecisÃµes rÃ¡pidas, gamificaÃ§Ã£o interna (equipe vÃª mÃ©tricas ao vivo).
**Stack**: FastAPI + WebSockets + Redis Pub/Sub.

### 3.3. Cohort Analysis Completo
**BenefÃ­cio**: Entender retenÃ§Ã£o, identificar meses de alta qualidade, calcular LTV.

### 3.4. Predictive Analytics
**Modelos prioritÃ¡rios**:
- Probabilidade de conversÃ£o (score 0-100 por sessÃ£o)
- Churn prediction (usuÃ¡rios que nÃ£o voltam)
- Trending products (produtos que vÃ£o viralizar)

**Stack**: Python (scikit-learn), PostgreSQL, cron daily.

### 3.5. Automated Insights
**Sistema que gera insights automaticamente**:
- "Post X teve CTR 3x maior que mÃ©dia - analisar o que funcionou"
- "TrÃ¡fego mobile aumentou 40% - otimizar mobile"
- "Produto Y tem alto trÃ¡fego mas baixo CTR - revisar CTA"

**ImplementaÃ§Ã£o**: Job diÃ¡rio que compara mÃ©tricas e gera relatÃ³rio.

### 3.6. Benchmarking Externo
**Comparar com concorrentes e indÃºstria**:
- Ahrefs/SEMrush: DR, keywords, backlinks
- SimilarWeb: TrÃ¡fego estimado de concorrentes
- Industry benchmarks: CTR mÃ©dio para nicho

### 3.7. Geolocation Analytics
**AnÃ¡lise por regiÃ£o/cidade**:
- Quais cidades geram mais conversÃµes?
- HorÃ¡rios de pico por timezone
- Produtos populares por regiÃ£o (Sul vs Nordeste)

**ImplementaÃ§Ã£o**: Capturar IP â†’ CloudFlare headers â†’ tabela `geo_data`.

### 3.8. Heatmaps & Session Recordings Integrados
**Microsoft Clarity** (gratuito) jÃ¡ mencionado no PRD.

**AnÃ¡lise adicional**: Exportar dados de Clarity para PostgreSQL via API para cruzar com outras mÃ©tricas.

### 3.9. Custom Attribution Model (Data-Driven)
**Machine Learning para atribuiÃ§Ã£o**:
- Treinar modelo com histÃ³rico de conversÃµes
- Aprender quais touchpoints sÃ£o mais importantes
- Alocar crÃ©dito proporcionalmente

**Requer**: 6-12 meses de dados, expertise em ML.

### 3.10. Data Democratization (Self-Service BI)
**Permitir que toda equipe acesse dados facilmente**:
- Looker Studio com acesso compartilhado
- Metabase self-hosted para queries SQL
- DocumentaÃ§Ã£o de tabelas e mÃ©tricas (data dictionary)

---

## 6. SUGESTÃ•ES DE MELHORIAS (10 identificadas)

### 4.1. KPIs - Adicionar Confidence Intervals
**SituaÃ§Ã£o Atual**: KPIs apresentados como nÃºmeros absolutos.
**SugestÃ£o**: Adicionar intervalos de confianÃ§a (IC 95%).

**Exemplo**:
```
CTR Afiliados: 4.5% (IC 95%: 4.1% - 4.9%)
Receita Mensal: R$ 1.847 (IC 95%: R$ 1.680 - R$ 2.014)
```

### 4.2. Metas SMART - Adicionar Baseline Real
**SituaÃ§Ã£o Atual**: Metas comeÃ§am do zero (baseline 0).
**SugestÃ£o**: ApÃ³s 30-60 dias, revisar baseline com dados reais e ajustar metas.

### 4.3. North Star Metric - Adicionar Leading Indicators
**SituaÃ§Ã£o Atual**: North Star = Receita mensal (lagging indicator).
**SugestÃ£o**: Adicionar leading indicators:
- CTR afiliados (prediz receita)
- SessÃµes orgÃ¢nicas (prediz CTR)
- Posts publicados (prediz sessÃµes)

### 4.4. Dashboards - Adicionar Comparativos HistÃ³ricos
**SituaÃ§Ã£o Atual**: MÃ©tricas absolutas.
**SugestÃ£o**: Sempre mostrar vs perÃ­odo anterior e vs mesmo perÃ­odo ano anterior.

### 4.5. Alertas - Implementar Machine Learning
**SituaÃ§Ã£o Atual**: Thresholds fixos (CTR < 2%, queda > 30%).
**SugestÃ£o**: ML para detectar anomalias baseado em padrÃµes histÃ³ricos (mais preciso).

### 4.6. SegmentaÃ§Ã£o - Adicionar RFM
**RFM** (Recency, Frequency, Monetary):
- **R**: Ãšltima visita (dias atrÃ¡s)
- **F**: FrequÃªncia de visitas (sessÃµes/mÃªs)
- **M**: Valor monetÃ¡rio (comissÃµes geradas)

**Segmentos**:
- Champions (RFM alto): 111, 112, 121, 122
- Loyal (FM alto, R mÃ©dio): 211, 212
- At Risk (R baixo, FM alto): 311, 312
- Lost (RFM baixo): 333

### 4.7. Testes A/B - Adicionar Multi-Armed Bandit
**SituaÃ§Ã£o Atual**: A/B tradicional (50/50 split).
**SugestÃ£o**: Multi-Armed Bandit aloca mais trÃ¡fego para variante vencedora dinamicamente.

### 4.8. Funis - Adicionar Drop-off Reasons
**SituaÃ§Ã£o Atual**: Funil mostra onde usuÃ¡rios saem.
**SugestÃ£o**: Capturar motivo (via hotjar, pesquisa exit-intent, session replay analysis).

### 4.9. Reports - Automatizar GeraÃ§Ã£o e Envio
**SituaÃ§Ã£o Atual**: PRD menciona reports mas nÃ£o automaÃ§Ã£o completa.
**SugestÃ£o**: n8n workflow que gera PDF do relatÃ³rio mensal e envia via email automaticamente dia 1 de cada mÃªs.

### 4.10. Data Catalog - Documentar Tabelas e MÃ©tricas
**SituaÃ§Ã£o Atual**: Sem documentaÃ§Ã£o centralizada de dados.
**SugestÃ£o**: Data dictionary em `/docs/analytics/data-catalog.md`:
```markdown
## Tabela: fact_sessions

**DescriÃ§Ã£o**: SessÃµes agregadas por hora para performance queries.

| Coluna | Tipo | DescriÃ§Ã£o | Exemplo |
|--------|------|-----------|---------|
| date | DATE | Data da sessÃ£o | 2025-12-10 |
| hour | SMALLINT | Hora (0-23) | 14 |
| post_id | UUID | ID do post visitado | abc-123... |
| device | VARCHAR(20) | mobile, desktop, tablet | mobile |
| sessions | INT | Total de sessÃµes | 42 |
| affiliate_clicks | INT | Cliques em afiliados | 3 |

**Refresh**: Atualizada a cada hora via cron.
**Owner**: Data Team
```

---

## 7. AMPLIAÃ‡Ã•ES DE ESCOPO (5 identificadas)

### 5.1. Data Warehouse (BigQuery)
**DescriÃ§Ã£o**: Export GA4 + tabelas PostgreSQL â†’ BigQuery para anÃ¡lises avanÃ§adas.
**Prioridade**: Alta (implementar Fase 2).
**Custo**: ~$50-200/mÃªs.

### 5.2. Machine Learning Platform
**DescriÃ§Ã£o**: Modelos preditivos (conversÃ£o, churn, trending products, personalizaÃ§Ã£o).
**Prioridade**: MÃ©dia (Fase 3, apÃ³s 6 meses de dados).
**Stack**: Python (scikit-learn, TensorFlow), Jupyter Notebooks, MLflow.

### 5.3. Customer Data Platform (CDP)
**DescriÃ§Ã£o**: Unificar dados de GA4, PostgreSQL, newsletter, redes sociais em perfil Ãºnico de usuÃ¡rio.
**BenefÃ­cios**: SegmentaÃ§Ã£o avanÃ§ada, personalizaÃ§Ã£o 1:1.
**Ferramentas**: Segment (paid), RudderStack (open-source).
**Prioridade**: Baixa (Fase 4, apÃ³s 12 meses).

### 5.4. Real-Time Event Streaming
**DescriÃ§Ã£o**: Kafka/Redis Streams para processar eventos em tempo real.
**BenefÃ­cios**: Dashboards ao vivo, recomendaÃ§Ãµes em tempo real.
**Prioridade**: Baixa (over-engineering para escala atual).

### 5.5. Data Science Team
**DescriÃ§Ã£o**: Contratar analista de dados dedicado (apÃ³s 12 meses).
**Responsabilidades**:
- AnÃ¡lises ad-hoc
- Experimentos A/B
- Machine Learning
- RelatÃ³rios executivos
**Prioridade**: MÃ©dia (quando receita justificar).

---

## 8. PLANO DE AÃ‡ÃƒO RECOMENDADO

### Curto Prazo (1-3 meses) - CRÃTICO

**ALTA Prioridade**:
- [ ] **Documentar tracking plan GA4** completo (todos os eventos + parÃ¢metros)
- [ ] **Criar tabelas fact_sessions e fact_affiliate_clicks** com Ã­ndices
- [ ] **Implementar 3 dashboards** (Executivo, Afiliados, ConteÃºdo)
- [ ] **Sistema de alertas bÃ¡sico** (Telegram: queda trÃ¡fego, CTR baixo, produtos indisponÃ­veis)
- [ ] **Configurar views materializadas** (mv_daily_post_performance)

**MÃ‰DIA Prioridade**:
- [ ] Documentar modelo de atribuiÃ§Ã£o (comeÃ§ar com Last-Click)
- [ ] Criar funÃ§Ãµes SQL para relatÃ³rios comuns (get_top_products_by_revenue)
- [ ] Setup Microsoft Clarity (heatmaps)

### MÃ©dio Prazo (3-6 meses)

**ImplementaÃ§Ãµes**:
- [ ] **Export GA4 â†’ BigQuery** + scheduled queries
- [ ] **Looker Studio dashboards** conectados ao BigQuery
- [ ] **Cohort analysis** completa (retenÃ§Ã£o, LTV)
- [ ] **Funis instrumentados** (GA4 + PostgreSQL)
- [ ] **Data quality monitoring** (jobs diÃ¡rios de validaÃ§Ã£o)
- [ ] **Automated insights** (job que gera insights semanais)

**Testes**:
- [ ] Framework A/B com significÃ¢ncia estatÃ­stica
- [ ] 5-10 experimentos rodando (CTAs, posicionamento, copy)

### Longo Prazo (6-12 meses)

**Grandes Projetos**:
- [ ] **Machine Learning models** (conversÃ£o, churn, trending)
- [ ] **Predictive analytics** em produÃ§Ã£o
- [ ] **Real-time dashboard** (WebSockets)
- [ ] **Attribution modeling** avanÃ§ado (Linear â†’ Data-Driven)
- [ ] **Data democratization** (Metabase self-service)
- [ ] **Contratar Data Analyst** dedicado

**OtimizaÃ§Ãµes**:
- [ ] Geolocation analytics (anÃ¡lise por regiÃ£o)
- [ ] RFM segmentation
- [ ] Multi-Armed Bandit A/B
- [ ] Data catalog completo

---

## 9. MÃ‰TRICAS DE SUCESSO

### KPIs de Analytics

| MÃ©trica | Baseline | 3 Meses | 6 Meses | 12 Meses |
|---------|----------|---------|---------|----------|
| **Data Quality Score** | - | 85% | 92% | 98% |
| **Dashboard Usage** (views/semana) | 0 | 50 | 150 | 300 |
| **Alertas Enviados** (por mÃªs) | 0 | 20 | 30 | 40 |
| **Insights AcionÃ¡veis** (por mÃªs) | 0 | 5 | 10 | 15 |
| **A/B Tests Rodando** (simultÃ¢neos) | 0 | 2 | 5 | 10 |
| **Query Response Time** (dashboard principal) | - | <3s | <2s | <1s |

### Impacto em KPIs de NegÃ³cio

**Expectativa**: Analytics robusto â†’ decisÃµes melhores â†’ mÃ©tricas melhores.

| KPI NegÃ³cio | Baseline | Com Analytics (+6 meses) | Melhoria |
|-------------|----------|--------------------------|----------|
| **CTR Afiliados** | 3% | 5-6% | +67-100% |
| **Receita/MÃªs** | R$ 1.000 | R$ 3.000-4.000 | +200-300% |
| **Tempo na PÃ¡gina** | 2min | 3min | +50% |
| **Taxa RejeiÃ§Ã£o** | 55% | 45% | -18% |

**CorrelaÃ§Ã£o**: Melhores dados â†’ melhores decisÃµes â†’ melhores resultados.

---

## 10. CONCLUSÃƒO

O geek.bidu.guru possui **KPIs bem definidos** mas **lacunas crÃ­ticas** na implementaÃ§Ã£o tÃ©cnica de analytics.

### AÃ§Ãµes Imediatas (30 dias):
1. âœ… **Tracking plan GA4** completo documentado
2. âœ… **Tabelas fact_sessions e fact_affiliate_clicks** criadas
3. âœ… **3 dashboards** operacionais (Executivo, Afiliados, ConteÃºdo)
4. âœ… **Sistema de alertas** Telegram (4 alertas prioritÃ¡rios)

### Quick Wins (90 dias):
1. ğŸ¯ **BigQuery export** (anÃ¡lises SQL avanÃ§adas)
2. ğŸ¯ **Cohort analysis** (entender retenÃ§Ã£o e LTV)
3. ğŸ¯ **Automated insights** (economia de tempo)
4. ğŸ¯ **Data quality monitoring** (confianÃ§a nos dados)

### Diferenciais (6-12 meses):
1. ğŸš€ **Machine Learning** (predictive analytics)
2. ğŸš€ **Real-time dashboard** (decisÃµes rÃ¡pidas)
3. ğŸš€ **Attribution avanÃ§ado** (Data-Driven)
4. ğŸš€ **Data Analyst** dedicado (anÃ¡lises profundas)

ImplementaÃ§Ã£o dessas sugestÃµes pode **3-5x a eficiÃªncia** na tomada de decisÃ£o e **aumentar receita 200-300%** via otimizaÃ§Ãµes data-driven.

---

**Analista**: Data Analyst
**Data**: 10/12/2025
**Status**: AnÃ¡lise Completa
